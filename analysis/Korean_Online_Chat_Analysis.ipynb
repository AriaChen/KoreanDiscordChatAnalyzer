{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1NETUgleJ0NK",
        "Ncsay1Z854R_",
        "g8AIs2cWQ3av",
        "HVqA4iRRBDCG",
        "EsUzswpVgASl",
        "TFvNAuLdhjeI"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "cYVzt4atYqeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Korean fonts Nanum for Google Colab, needs to restart runtime after installation"
      ],
      "metadata": {
        "id": "I4v5JHx5S2hO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "id": "fsiVocYw-RUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "id": "hdOQV26APfzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.font_manager as fm\n",
        "from transformers import pipeline\n",
        "from collections import Counter\n",
        "from konlpy.tag import Okt\n",
        "from wordcloud import WordCloud\n",
        "from PIL import Image\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic') # set font to display Korean characters"
      ],
      "metadata": {
        "id": "4-ozJlMVJ2CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File Processing"
      ],
      "metadata": {
        "id": "zE7RHgPI-0iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ajdK2cGWZI5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/cleaned_chat_data.csv')"
      ],
      "metadata": {
        "id": "_2H9lm28Zc4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Content Validity Check"
      ],
      "metadata": {
        "id": "D2nz-NLu3D5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if each row in the 'Content' column is valid (not NaN or None)\n",
        "df['isValidContent'] = df['Content'].apply(lambda x: not pd.isna(x))\n",
        "\n",
        "# Count the number of lines\n",
        "num_lines = df.shape[0]\n",
        "# Count the number of valid lines\n",
        "num_valid_lines = df['isValidContent'].sum()\n",
        "\n",
        "# Print the number of valid lines\n",
        "print(f\"Number of lines: {num_lines}, Number of valid lines in 'Content': {num_valid_lines}\")\n",
        "\n",
        "# Drop the 'isValidContent' column from the DataFrame\n",
        "df.drop(columns=['isValidContent'], inplace=True)"
      ],
      "metadata": {
        "id": "VsALzHhW3C3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monthly Analysis"
      ],
      "metadata": {
        "id": "5zdQAivMcJkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure that 'Timestamp' is a DateTime object\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "\n",
        "# Extract the year and month from 'Timestamp'\n",
        "df['YearMonth'] = df['Timestamp'].dt.to_period('M')\n",
        "\n",
        "# List all the available months\n",
        "# Get unique YearMonth values\n",
        "unique_yearmonths = df['YearMonth'].unique()\n",
        "print(unique_yearmonths)"
      ],
      "metadata": {
        "id": "dIvlGq_X9fuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_data_by_month(df, year_month_str):\n",
        "    \"\"\"Filter the DataFrame for the given year and month.\"\"\"\n",
        "    try:\n",
        "        year_month = pd.Period(year_month_str, freq='M')\n",
        "    except:\n",
        "        print(f\"Invalid input format. Please use 'YYYY-MM' format.\")\n",
        "        return None\n",
        "\n",
        "    if year_month not in df['YearMonth'].values:\n",
        "        print(f\"The month {year_month} does not exist in the dataset.\")\n",
        "        return None\n",
        "\n",
        "    # Filter the data for the given year and month\n",
        "    return df[df['YearMonth'] == year_month]"
      ],
      "metadata": {
        "id": "zMKWkMvGGysX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "E75zvR7gqAvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stop Words"
      ],
      "metadata": {
        "id": "5bMpc2dZnjGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of words to be excluded\n",
        "stop_words = set(['저', '거', '뭐', '것', '그', '수', '더', '지금', '분', '그냥', '요',\n",
        "                  '제', '때', '혹시', '왜', '이', '좀', '해', '네', '안',\n",
        "                  '가요', '다시', '해당', '용', '넵', '전', '오', '또', '개',\n",
        "                  '오늘', '정도', '말씀', '말', '나', '내', '건가', '명',\n",
        "                  '넹', '은', '및', '알', '데', '중', '도', '건', '로',\n",
        "                  '게', '를', '여'])"
      ],
      "metadata": {
        "id": "VBqe6xlunkov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Okt Tokenizer"
      ],
      "metadata": {
        "id": "YD1JK6ETqCga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer\n",
        "okt = Okt()\n",
        "\n",
        "def tokenize(text):\n",
        "    # Extract nouns\n",
        "    return [word for word in okt.nouns(text) if word not in stop_words]"
      ],
      "metadata": {
        "id": "QWt-FfrrqExV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Frequency over Time"
      ],
      "metadata": {
        "id": "1NETUgleJ0NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_messages(dataframe, frequency):\n",
        "    # Resample and count messages\n",
        "    resampled_data = dataframe.resample(frequency, on='Timestamp').count()\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    ax = plt.gca()  # Get current axis\n",
        "    resampled_data['Content'].plot(kind='bar', ax=ax)\n",
        "\n",
        "    # Manually setting x-tick labels\n",
        "    if frequency in ['D', 'W', 'M']:\n",
        "        ax.set_xticks(range(len(resampled_data)))\n",
        "        ax.set_xticklabels([date.strftime('%Y-%m-%d') if frequency in ['D', 'W']\n",
        "                            else date.strftime('%Y-%m')\n",
        "                            for date in resampled_data.index])\n",
        "\n",
        "    # Rotate and align the tick labels\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
        "\n",
        "    plt.title(f'Number of Messages Sent Over Time ({frequency})')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Number of Messages')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "cGUobDrWJ0kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M')\n",
        "\n",
        "# plot_messages(df, 'D')  # for daily\n",
        "plot_messages(df, 'W')  # for weekly\n",
        "plot_messages(df, 'M')  # for monthly"
      ],
      "metadata": {
        "id": "VrXakjh_bGKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Most Active Users"
      ],
      "metadata": {
        "id": "Ncsay1Z854R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Author' and count the number of posts\n",
        "author_post_counts = df.groupby('Author').size()\n",
        "\n",
        "# Sort the authors by the number of posts in descending order and select the top 20\n",
        "top_authors = author_post_counts.sort_values(ascending=False).head(20)"
      ],
      "metadata": {
        "id": "_kTPU2fP567X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))  # Increased figure size\n",
        "top_authors.plot(kind='bar', align='center')\n",
        "\n",
        "plt.title('Number of Posts by Top 20 Authors')\n",
        "plt.xlabel('Author')\n",
        "plt.ylabel('Number of Posts')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()  # Adjust layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mWkQBGpB6jXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 20 Active Users per Month"
      ],
      "metadata": {
        "id": "QOVha2aK9i92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'YearMonth' and 'Author', and count the number of posts\n",
        "author_post_counts = df.groupby(['YearMonth', 'Author']).size().reset_index(name='PostCount')"
      ],
      "metadata": {
        "id": "nG_ucVLi_6yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot top 20 authors for a given year and month\n",
        "def plot_top_authors_for_month(df, year_month_str):\n",
        "    month_data = filter_data_by_month(df, year_month_str)\n",
        "    if month_data is None:\n",
        "        return\n",
        "\n",
        "    # Get the top 20 authors for the month\n",
        "    top_authors = month_data.sort_values(by='PostCount', ascending=False).head(20)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    top_authors.set_index('Author')['PostCount'].plot(kind='bar')\n",
        "    plt.title(f'Top 20 Authors in {year_month_str}')\n",
        "    plt.xlabel('Author')\n",
        "    plt.ylabel('Number of Posts')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bpsfiQBp8u7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "plot_top_authors_for_month(author_post_counts, '2023-07')  # Replace with the desired year-month"
      ],
      "metadata": {
        "id": "l5QVPKoI872u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Term Frequency"
      ],
      "metadata": {
        "id": "g8AIs2cWQ3av"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 20 Terms per Month"
      ],
      "metadata": {
        "id": "rkfb5F4acsv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bar Chart"
      ],
      "metadata": {
        "id": "9-pE5zRpTtE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate bar chart for top frequent terms for a given year and month\n",
        "def plot_top_terms_for_month(df, year_month_str):\n",
        "    month_data = filter_data_by_month(df, year_month_str)\n",
        "    if month_data is None:\n",
        "        return\n",
        "\n",
        "    # Tokenize and count terms\n",
        "    terms = month_data['Content'].apply(tokenize).sum()\n",
        "    term_counts = Counter(terms)\n",
        "\n",
        "    # Get the most common terms\n",
        "    most_common_terms = term_counts.most_common(20)\n",
        "\n",
        "    # Prepare data for visualization\n",
        "    terms, counts = zip(*most_common_terms)\n",
        "\n",
        "    # Create a bar chart\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(terms, counts)\n",
        "    plt.title(f'Top 20 Frequent Terms in {year_month_str}')\n",
        "    plt.xlabel('Terms')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6FrcX1yudFsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "plot_top_terms_for_month(df, '2023-12')  # Replace with the desired year-month"
      ],
      "metadata": {
        "id": "8_6qlP9YdI9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Cloud"
      ],
      "metadata": {
        "id": "buLnCNYLTu7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load mask image\n",
        "mask_image = np.array(Image.open('/content/bear.jpg'))"
      ],
      "metadata": {
        "id": "Gx0X_1U1Tw8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a word cloud for a given year and month\n",
        "def generate_wordcloud_for_month(df, year_month_str, mask):\n",
        "    month_data = filter_data_by_month(df, year_month_str)\n",
        "    if month_data is None:\n",
        "        return\n",
        "\n",
        "    # Tokenize and count terms, filtering out stop words\n",
        "    terms = month_data['Content'].apply(tokenize).sum()\n",
        "    term_string = ' '.join(terms)  # Join all terms into a single string\n",
        "\n",
        "    # Generate a word cloud\n",
        "    wordcloud = WordCloud(font_path='/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',\n",
        "                          width=800, height=800,\n",
        "                          background_color='white',\n",
        "                          max_font_size=160,\n",
        "                          mask=mask).generate(term_string)\n",
        "\n",
        "    # Display the word cloud\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Word Cloud for {year_month_str}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7Y1zVkGaQMr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "generate_wordcloud_for_month(df, '2023-12', mask_image)  # Replace with the desired year-month"
      ],
      "metadata": {
        "id": "7AN0uOfaQkVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "HVqA4iRRBDCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "HB5eRhEngQTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_excel('/content/sentiment_analysis_test.xlsx')\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "r29G5NgWgnKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WhitePeak/bert-base-cased-Korean-sentiment\n",
        "\n",
        "LABEL_0: negative,\n",
        "LABEL_1: positive.  \n",
        "\n",
        "Accuracy Result on test dataset: 70%."
      ],
      "metadata": {
        "id": "EsUzswpVgASl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_pipeline = pipeline(model=\"WhitePeak/bert-base-cased-Korean-sentiment\")"
      ],
      "metadata": {
        "id": "qjrQQ9R1BR_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to apply the sentiment pipeline and determine the label\n",
        "def get_sentiment_label(text):\n",
        "    # Truncate the text to the maximum length of the model (512 tokens)\n",
        "    result = sentiment_pipeline(text, truncation=True)[0]\n",
        "    label = result['label'][-1]\n",
        "    score = result['score']\n",
        "\n",
        "    # Set label to 2 (neutral) if score is less than 0.6\n",
        "    if score < 0.6:\n",
        "        label = '2'\n",
        "    return label"
      ],
      "metadata": {
        "id": "3TOV1T9vz1uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply to test dataset"
      ],
      "metadata": {
        "id": "XgFWa7cU4SVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the sentiment_pipeline to each row in the 'text' column\n",
        "test_df[['predicted_label']] = test_df['Text'].apply(\n",
        "    lambda x: pd.Series(get_sentiment_label(x))\n",
        ")"
      ],
      "metadata": {
        "id": "CA3rq7uhxpbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'predicted_label' from object to int\n",
        "test_df['predicted_label'] = test_df['predicted_label'].astype(int)\n",
        "# Compare the predicted labels with the actual labels\n",
        "test_df['is_correct'] = test_df['predicted_label'] == test_df['Label']\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = test_df['is_correct'].mean()\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "V3ZWOb8y0ViN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply to original dataset"
      ],
      "metadata": {
        "id": "2WkbBkvs4V2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the sentiment_pipeline to each row in the 'Content' column\n",
        "df[['Sentiment']] = df['Content'].apply(\n",
        "    lambda x: pd.Series(get_sentiment_label(x))\n",
        ")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Save the result back to the CSV\n",
        "df.to_csv('/content/drive/MyDrive/cleaned_chat_data_with_sentiments.csv', index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "wJLb_qvR4EdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatGPT - GPT4\n",
        "\n",
        "Simply asked GPT-4 to label the test data with negative (0), positive (1), or neutral (2)\n",
        "\n",
        "Accuracy Result on test dataset: 100%.\n",
        "\n",
        "\n",
        "**Reference:**\n",
        "\n",
        "* Gilardi, Fabrizio, Meysam Alizadeh, and Maël Kubli. \"Chatgpt outperforms crowd-workers for text-annotation tasks.\" arXiv preprint arXiv:2303.15056 (2023)."
      ],
      "metadata": {
        "id": "36-yn_x21_nb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "TFvNAuLdhjeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data with sentiment\n",
        "df_sentiment = pd.read_csv('/content/drive/MyDrive/cleaned_chat_data_with_sentiments.csv', encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "nlXEV50UivaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map the numerical labels to descriptive names\n",
        "sentiment_label_map = {\n",
        "    0: 'Negative',\n",
        "    1: 'Positive',\n",
        "    2: 'Neutral'\n",
        "}\n",
        "df_sentiment['Sentiment'] = df_sentiment['Sentiment'].map(sentiment_label_map)\n",
        "\n",
        "# Count the frequency of each sentiment label\n",
        "sentiment_counts = df_sentiment['Sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "APpUS-Mvi6kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pie chart\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Distribution of Sentiments', pad=20)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures the pie chart is circular.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xMcVTO9ohk_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modeling"
      ],
      "metadata": {
        "id": "pqOMZOX8qAk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latent Dirichlet Allocation (LDA)"
      ],
      "metadata": {
        "id": "OP_16PF02HUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visuaization"
      ],
      "metadata": {
        "id": "Km-nEeAADnRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_top_words(model, n_topics, feature_names, n_top_words, title):\n",
        "    fig, axes = plt.subplots(1, n_topics, figsize=(25, 5), sharex=True) # 1 row, n_topics subfigures\n",
        "    axes = axes.flatten()\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        top_features_ind = topic.argsort()[-n_top_words:]\n",
        "        top_features = feature_names[top_features_ind]\n",
        "        weights = topic[top_features_ind]\n",
        "\n",
        "        ax = axes[topic_idx]\n",
        "        ax.barh(top_features, weights, height=0.7)\n",
        "        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 18})\n",
        "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=15)\n",
        "        for i in \"top right left\".split():\n",
        "            ax.spines[i].set_visible(False)\n",
        "        fig.suptitle(title, fontsize=24, y=1.05) # Increasing the y value moves the title higher\n",
        "\n",
        "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fQ5il-mj_wrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA Analysis for a Specific Month\n",
        "\n",
        "* Here we treat each text as a document"
      ],
      "metadata": {
        "id": "Pcu_mrvJKJjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lda_analysis_for_month(df, year_month_str, n_topics=5, n_top_words=10):\n",
        "    # Filter data for the specified month\n",
        "    month_data = filter_data_by_month(df, year_month_str)\n",
        "    if month_data is None:\n",
        "        return\n",
        "\n",
        "    month_data_LDA = month_data.copy() # create a copy of dataframe for analysis\n",
        "\n",
        "    # Tokenize and prepare text data\n",
        "    # Join tokens into a string for LDA analysis\n",
        "    month_data_LDA['tokenized_content'] = month_data_LDA['Content'].apply(\n",
        "        lambda x: ' '.join(tokenize(x)) if pd.notnull(x) else ''\n",
        "    )\n",
        "\n",
        "    # Convert a collection of texts to a matrix of token counts\n",
        "    # vocabulary with top max_features, appearing more than min_df times\n",
        "    vectorizer = CountVectorizer(\n",
        "        max_df=0.95, min_df=2,\n",
        "        max_features=2500\n",
        "        )\n",
        "    X = vectorizer.fit_transform(month_data_LDA['tokenized_content'])\n",
        "\n",
        "    # Perform LDA\n",
        "    lda = LatentDirichletAllocation(\n",
        "        n_components=n_topics,\n",
        "        max_iter=50, # epochs\n",
        "        random_state=0 # for reproducible results\n",
        "        )\n",
        "    t0 = time()\n",
        "    lda.fit(X)\n",
        "    print(\"LDA done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "    # Plot the top words for each topic\n",
        "    plot_top_words(\n",
        "        lda, n_topics, vectorizer.get_feature_names_out(), n_top_words,\n",
        "        f\"Top {n_top_words} words for topics in {year_month_str}\"\n",
        "        )"
      ],
      "metadata": {
        "id": "EM1eDJTz-Pkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_analysis_for_month(df, '2023-12', n_topics=5, n_top_words=10)"
      ],
      "metadata": {
        "id": "MZfV7PlWKmsk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}